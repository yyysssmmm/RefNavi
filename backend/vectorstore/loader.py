import json
from typing import List
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

def load_metadata_as_documents(json_path: str) -> List[Document]:
    """
    í†µí•© ë©”íƒ€ë°ì´í„°(JSON) â†’ LangChain Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    - ë³¸ë¬¸ì€ chunking í›„ ê° chunkë§ˆë‹¤ Documentë¡œ ì €ì¥
    - referenceëŠ” í•˜ë‚˜ì”© Documentë¡œ ì €ì¥
    """
    documents = []

    with open(json_path, "r", encoding="utf-8") as f:
        metadata = json.load(f)

    # âœ… ë³¸ë¬¸ chunking
    paper_title = metadata.get("title", "").strip()
    abstract_original = metadata.get("abstract_original", "").strip()
    abstract_llm = metadata.get("abstract_llm", "").strip()
    body_text = metadata.get("body_fixed", "").strip()

    # chunking
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    body_chunks = text_splitter.create_documents([body_text])

    for idx, chunk in enumerate(body_chunks):
        chunk.metadata = {
            "source": "original_paper_body",
            "title": paper_title,
            "chunk_id": idx
        }
        documents.append(chunk)

    # âœ… abstract í†µí•© Document í•˜ë‚˜ ì¶”ê°€
    full_original_text = f"""[Original Paper]
Title: {paper_title}

Abstract (Original):
{abstract_original}

Abstract (LLM Summary):
{abstract_llm}
"""
    documents.append(Document(
        page_content=full_original_text.strip(),
        metadata={"source": "original paper", "title": paper_title}
    ))

    # âœ… reference ë…¼ë¬¸ ì²˜ë¦¬
    references = metadata.get("references", [])
    for ref in references:
        title = ref.get("ref_title") or ""
        abstract = ref.get("abstract") or ""
        ref_num = ref.get("ref_number") or ""
        citation_contexts = [ctx for ctx in ref.get("citation_contexts", []) if ctx.strip()]
        citation_text = "\n".join(f"- {ctx}" for ctx in citation_contexts) or "N/A"

        page_content = f"""[Reference Paper]
Title: {title}
Abstract: {abstract}
Citation Contexts:
{citation_text}
"""

        doc_metadata = {
            "ref_num": ref_num,
            "title": title,
            "year": str(ref.get("year") or "unknown"),
            "authors": ", ".join(ref.get("authors", [])) if isinstance(ref.get("authors", []), list) else "-",
            "doi": ref.get("doi") or "",
            "citation_count": int(ref.get("citation_count") or 0),
            "source": "reference paper"
        }

        documents.append(Document(page_content=page_content.strip(), metadata=doc_metadata))

    return documents


# âœ… ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    test_path = "../utils/integrated_metadata.json"
    docs = load_metadata_as_documents(test_path)

    print(f"\nğŸ“„ ì´ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}ê°œ (ì—…ë¡œë“œ ë…¼ë¬¸ì˜ ë³¸ë¬¸ chunk + ì—…ë¡œë“œ ë…¼ë¬¸ì˜ ì œëª© ë° abstract + references)")
    print("\nğŸ“Œ ì²« ë²ˆì§¸ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°:")
    print(f"source: {docs[0].metadata.get('source')}")
    print(f"title: {docs[0].metadata.get('title')}")
    print("\nğŸ“„ ë³¸ë¬¸ ë‚´ìš© (ì• 500ì):")
    print(docs[0].page_content[:500] + "...\n")
