import os
import json
import time
import requests
from typing import List, Dict, Optional
from difflib import SequenceMatcher

# ğŸ”„ inverted_indexì—ì„œ abstract ì¬êµ¬ì„±
def reconstruct_abstract(index: Dict[str, List[int]]) -> str:
    if not index:
        return ""
    tokens = ["" for _ in range(max(i for v in index.values() for i in v) + 1)]
    for word, positions in index.items():
        for pos in positions:
            tokens[pos] = word
    return " ".join(tokens)

# ğŸ” OpenAlex ê¸°ë°˜ ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰
def search_openalex_metadata(title: str) -> Optional[Dict]:
    try:
        url = "https://api.openalex.org/works"
        params = {"search": title, "per_page": 5}
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()

        if 'results' in data and data['results']:
            def similarity(a, b):
                return SequenceMatcher(None, a.lower(), b.lower()).ratio()

            best = max(data['results'], key=lambda x: similarity(x.get("title", ""), title))
            if similarity(best.get("title", ""), title) > 0.6:
                return {
                    "title": best.get("title"),
                    "abstract": reconstruct_abstract(best.get("abstract_inverted_index")),
                    "doi": best.get("doi"),
                    "year": best.get("publication_year"),
                    "authors": [a['author']['display_name'] for a in best.get("authorships", [])],
                    "citation_count": best.get("cited_by_count"),
                }
    except Exception as e:
        print(f"âŒ OpenAlex ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    return None

# ğŸ§  ì „ì²´ íŒŒì´í”„ë¼ì¸: ì œëª© ê¸°ë°˜ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
def fetch_metadata_from_titles(refs: List[Dict[str, str]], save_path="openalex_metadata.jsonl") -> List[Dict]:
    results = []
    for i, ref_obj in enumerate(refs, start=1):
        title = ref_obj.get("ì œëª©", "").strip()
        if not title:
            print(f"âš ï¸ ì œëª© ì—†ìŒ â†’ ìŠ¤í‚µ (#{i})")
            continue

        print(f"ğŸ” [{i}] ì œëª© ê²€ìƒ‰ ì¤‘: {title}")
        metadata = search_openalex_metadata(title)
        if metadata:
            results.append(metadata)
            print(f"âœ… ê²€ìƒ‰ ì„±ê³µ: {metadata.get('title')}")
        else:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {title}")
        time.sleep(1)  # OpenAlex API ë‚¨ìš© ë°©ì§€

    with open(save_path, "w", encoding="utf-8") as f:
        for item in results:
            formatted = {
                "title": item.get("title", ""),
                "abstract": item.get("abstract", ""),
                "doi": item.get("doi", ""),
                "year": item.get("year", None),
                "authors": item.get("authors", []),
                "citation_count": item.get("citation_count", 0)
            }
            f.write(json.dumps(formatted, ensure_ascii=False) + "\n")

    print(f"\nğŸ“ ì´ {len(results)}ê°œ ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ â†’ {save_path}")
    return results

# âœ… ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    from pprint import pprint

    refs = [
        {
            "ì œëª©": "Layer normalization",
            "ì°¸ì¡°ë‚´ìš©": "[1] JimmyLeiBa,JamieRyanKiros,andGeoffreyEHinton. Layernormalization. arXivpreprint arXiv:1607.06450,2016."
        },
        {
            "ì œëª©": "Neural machine translation by jointly learning to align and translate",
            "ì°¸ì¡°ë‚´ìš©": "[2] DzmitryBahdanau,KyunghyunCho,andYoshuaBengio. Neuralmachinetranslationbyjointly learningtoalignandtranslate. CoRR,abs/1409.0473,2014."
        },
        {
            "ì œëª©": "Massive exploration of neural machine translation architectures",
            "ì°¸ì¡°ë‚´ìš©": "[3] DennyBritz,AnnaGoldie,Minh-ThangLuong,andQuocV.Le. Massiveexplorationofneural machinetranslationarchitectures. CoRR,abs/1703.03906,2017."
        },
        {
            "ì œëª©": "Long short-term memory-networks for machine reading",
            "ì°¸ì¡°ë‚´ìš©": "[4] JianpengCheng,LiDong,andMirellaLapata. Longshort-termmemory-networksformachine reading. arXivpreprintarXiv:1601.06733,2016."
        },
        {
            "ì œëª©": "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
            "ì°¸ì¡°ë‚´ìš©": "[5] KyunghyunCho,BartvanMerrienboer,CaglarGulcehre,FethiBougares,HolgerSchwenk, andYoshuaBengio. Learningphraserepresentationsusingrnnencoder-decoderforstatistical machinetranslation. CoRR,abs/1406.1078,2014."
        }
    ]

    metadata_list = fetch_metadata_from_titles(refs)
    pprint(metadata_list)
