#!/usr/bin/env python3
"""
arXiv HTML í¬ë¡¤ëŸ¬ - Attention Is All You Need ë…¼ë¬¸ êµ¬ì¡° ë¶„ì„
ì„¹ì…˜ë³„ë¡œ ì¸ìš© ë¬¸ì¥ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ ì €ì¥
"""

import requests
import json
import re
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
import os

class ArxivHTMLCrawler:
    def __init__(self, arxiv_id: str = "1706.03762v7"):
        self.arxiv_id = arxiv_id
        self.base_url = f"https://arxiv.org/html/{arxiv_id}"
        self.headers = {
            'User-Agent': 'RefNavi/1.0 (academic research tool)',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
        }
    
    def fetch_html(self) -> BeautifulSoup:
        """arXiv HTML í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ì„œ BeautifulSoup ê°ì²´ë¡œ ë°˜í™˜"""
        print(f"ğŸ” arXiv HTML í˜ì´ì§€ ìš”ì²­: {self.base_url}")
        
        response = requests.get(self.base_url, headers=self.headers, timeout=30)
        
        if response.status_code == 200:
            print(f"âœ… HTML í˜ì´ì§€ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì˜´ (í¬ê¸°: {len(response.content)} bytes)")
            return BeautifulSoup(response.content, 'html.parser')
        else:
            raise Exception(f"âŒ HTML ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
    
    def extract_sections(self, soup: BeautifulSoup) -> List[Dict]:
        """ë¬¸ì„œì˜ ëª¨ë“  ì„¹ì…˜ê³¼ ì„œë¸Œì„¹ì…˜ì„ ì¶”ì¶œ"""
        print("ğŸ“– ì„¹ì…˜ êµ¬ì¡° ë¶„ì„ ì¤‘...")
        
        sections = []
        
        # ì„¹ì…˜ê³¼ ì„œë¸Œì„¹ì…˜ ì œëª© ì°¾ê¸°
        section_titles = soup.find_all(['h2', 'h3', 'h4'], 
                                      class_=lambda x: x and ('ltx_title_section' in x or 'ltx_title_subsection' in x))
        
        print(f"ğŸ¯ ë°œê²¬ëœ ì„¹ì…˜/ì„œë¸Œì„¹ì…˜ ì œëª©: {len(section_titles)}ê°œ")
        
        # ì„¹ì…˜ ë²ˆí˜¸ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ subsectionì´ ìˆìœ¼ë©´ sectionì€ ì œì™¸í•˜ì§€ë§Œ ê³„ì¸µ ì •ë³´ëŠ” ë³´ì¡´
        section_groups = {}
        section_hierarchy = {}  # ë¶€ëª¨ ì„¹ì…˜ ì •ë³´ ì €ì¥
        
        for i, title_elem in enumerate(section_titles):
            section_text = title_elem.get_text(strip=True)
            class_list = title_elem.get('class', [])
            
            # ì„¹ì…˜ íƒ€ì… íŒë³„
            if 'ltx_title_section' in class_list:
                section_type = 'section'
            elif 'ltx_title_subsection' in class_list:
                section_type = 'subsection'
            else:
                continue
            
            # ì„¹ì…˜ ë²ˆí˜¸ ì¶”ì¶œ
            section_match = re.match(r'^(\d+(?:\.\d+)*)', section_text)
            if section_match:
                section_number = section_match.group(1)
                base_section_number = section_number.split('.')[0]  # ê¸°ë³¸ ì„¹ì…˜ ë²ˆí˜¸ (ì˜ˆ: "3.1" -> "3")
                
                if base_section_number not in section_groups:
                    section_groups[base_section_number] = {'sections': [], 'subsections': []}
                
                section_info = {
                    'index': i,
                    'element': title_elem,
                    'section_number': section_number,
                    'section_title': section_text.replace(section_number, '').strip(),
                    'full_title': section_text,
                    'section_type': section_type
                }
                
                if section_type == 'section':
                    section_groups[base_section_number]['sections'].append(section_info)
                    # ë¶€ëª¨ ì„¹ì…˜ ì •ë³´ ì €ì¥
                    section_hierarchy[base_section_number] = {
                        'parent_section_number': section_number,
                        'parent_section_title': section_text.replace(section_number, '').strip(),
                        'parent_full_title': section_text
                    }
                else:
                    section_groups[base_section_number]['subsections'].append(section_info)
        
        # subsectionì´ ìˆìœ¼ë©´ í•´ë‹¹ sectionì€ ì œì™¸í•˜ê³  subsectionë§Œ í¬í•¨í•˜ë˜, ë¶€ëª¨ ì •ë³´ ì¶”ê°€
        for base_num, group in section_groups.items():
            if group['subsections']:
                # subsectionì´ ìˆìœ¼ë©´ subsectionë§Œ ì¶”ê°€í•˜ë˜ ë¶€ëª¨ ì •ë³´ í¬í•¨
                parent_info = section_hierarchy.get(base_num, {})
                for subsection in group['subsections']:
                    # ë¶€ëª¨ ì„¹ì…˜ ì •ë³´ ì¶”ê°€
                    subsection['parent_section'] = parent_info
                sections.extend(group['subsections'])
                print(f"  ğŸ“ ì„¹ì…˜ {base_num}: subsectionë§Œ ì²˜ë¦¬ ({len(group['subsections'])}ê°œ) - ë¶€ëª¨: {parent_info.get('parent_full_title', 'Unknown')}")
            else:
                # subsectionì´ ì—†ìœ¼ë©´ section ì¶”ê°€
                sections.extend(group['sections'])
                print(f"  ğŸ“„ ì„¹ì…˜ {base_num}: section ì²˜ë¦¬ ({len(group['sections'])}ê°œ)")
        
        # ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬
        sections.sort(key=lambda x: x['index'])
        
        for i, section in enumerate(sections):
            parent_info = section.get('parent_section', {})
            if parent_info:
                print(f"  {i+1}. [{section['section_type']}] {parent_info.get('parent_full_title', '')} > {section['full_title']}")
            else:
                print(f"  {i+1}. [{section['section_type']}] {section['full_title']}")
        
        return sections
    
    def extract_section_content(self, section_elem, next_section_elem=None) -> Dict:
        """íŠ¹ì • ì„¹ì…˜ì˜ ë‚´ìš©ê³¼ ì¸ìš© ì •ë³´ë¥¼ ì¶”ì¶œ"""
        
        # ì„¹ì…˜ ì‹œì‘ ìš”ì†Œë¶€í„° ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ ì „ê¹Œì§€ì˜ ëª¨ë“  ë‚´ìš© ìˆ˜ì§‘
        content_elements = []
        current_elem = section_elem
        
        # í˜„ì¬ ì„¹ì…˜ ìš”ì†Œì˜ ë¶€ëª¨ë¥¼ ì°¾ì•„ì„œ ë” ë„“ì€ ë²”ìœ„ë¡œ íƒìƒ‰
        parent_elem = section_elem.parent
        if parent_elem:
            # ë¶€ëª¨ ë‚´ì˜ ëª¨ë“  ìì‹ ìš”ì†Œë¥¼ ìˆœíšŒ
            found_start = False
            for child in parent_elem.children:
                if hasattr(child, 'name') and child.name:
                    # í˜„ì¬ ì„¹ì…˜ ì œëª©ì„ ì°¾ì•˜ìœ¼ë©´ ë‹¤ìŒ ìš”ì†Œë“¤ë¶€í„° ìˆ˜ì§‘
                    if child == section_elem:
                        found_start = True
                        continue
                    
                    # ë‹¤ìŒ ì„¹ì…˜ ì œëª©ì´ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨
                    if found_start and next_section_elem and child == next_section_elem:
                        break
                    
                    # ë‹¤ë¥¸ ì„¹ì…˜/ì„œë¸Œì„¹ì…˜ ì œëª©ì´ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨
                    if found_start and child.name in ['h2', 'h3', 'h4']:
                        class_list = child.get('class', [])
                        if any('ltx_title' in cls for cls in class_list):
                            break
                    
                    # ìˆ˜ì§‘ ì‹œì‘ëœ í›„ë¼ë©´ ë‚´ìš© ìš”ì†Œ ì¶”ê°€
                    if found_start:
                        content_elements.append(child)
        
        # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ - ë” í¬ê´„ì ìœ¼ë¡œ
        full_text = ""
        paragraphs = []
        table_contexts = []  # í‘œ ê´€ë ¨ ì •ë³´ ì €ì¥
        
        for elem in content_elements:
            # í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ëª¨ë“  ìš”ì†Œì—ì„œ ë‚´ìš© ì¶”ì¶œ
            elem_text = elem.get_text(strip=True) if hasattr(elem, 'get_text') else str(elem).strip()
            
            # í‘œ(table) ìš”ì†Œ íŠ¹ë³„ ì²˜ë¦¬
            if elem.name == 'table' or (hasattr(elem, 'find') and elem.find('table')):
                table_text = elem.get_text(strip=True)
                if table_text and len(table_text) > 20:
                    # í‘œ ìº¡ì…˜ ì°¾ê¸°
                    caption = ""
                    caption_elem = elem.find('caption') or elem.find_previous('caption') or elem.find_next('caption')
                    if caption_elem:
                        caption = caption_elem.get_text(strip=True)
                    
                    table_contexts.append({
                        "table_text": table_text,
                        "caption": caption,
                        "citations": re.findall(r'\[(\d+(?:,\s*\d+)*)\]', table_text)
                    })
                    
                    paragraphs.append(f"[TABLE] {caption}: {table_text}")
                    full_text += f"[TABLE] {caption}: {table_text} "
            
            elif elem_text and len(elem_text) > 10:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ
                # íŠ¹ì • íƒœê·¸ë“¤ì€ ê°œë³„ ë¬¸ë‹¨ìœ¼ë¡œ ì²˜ë¦¬
                if elem.name in ['p', 'div', 'section', 'article']:
                    paragraphs.append(elem_text)
                    full_text += elem_text + " "
                # ê¸°íƒ€ ìš”ì†Œë“¤ë„ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í¬í•¨
                elif elem_text not in full_text:  # ì¤‘ë³µ ë°©ì§€
                    paragraphs.append(elem_text)
                    full_text += elem_text + " "
        
        # ë¬¸ë‹¨ì´ ë¹„ì–´ìˆë‹¤ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ì²˜ë¦¬
        if not paragraphs and full_text.strip():
            paragraphs = [full_text.strip()]
        
        # ì¸ìš© ë¶„ì„
        all_citations = set()
        citation_sentences = []
        
        for paragraph_text in paragraphs:
            # ë¬¸ì¥ ë¶„ë¦¬
            sentences = re.split(r'[.!?]+\s+', paragraph_text)
            
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 10:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
                    continue
                    
                # ì—¬ëŸ¬ ì¸ìš© íŒ¨í„´ì„ ëª¨ë‘ ì°¾ê¸°
                citation_pattern = r'\[(\d+(?:,\s*\d+)*)\]'
                citations_in_sentence = re.findall(citation_pattern, sentence)
                
                if citations_in_sentence:
                    # ê° ì¸ìš© ê·¸ë£¹ì„ ê°œë³„ ë²ˆí˜¸ë¡œ ë¶„ë¦¬
                    all_citation_numbers = []
                    for citation_group in citations_in_sentence:
                        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì¸ìš© ë²ˆí˜¸ë“¤ ë¶„ë¦¬
                        citation_numbers = [num.strip() for num in citation_group.split(',')]
                        all_citation_numbers.extend(citation_numbers)
                    
                    # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€
                    unique_citations = []
                    for num in all_citation_numbers:
                        if num not in unique_citations:
                            unique_citations.append(num)
                    
                    if unique_citations:
                        # ë¬¸ë§¥ ìœ í˜• íŒë³„ (í‘œ, ê·¸ë¦¼, ì¼ë°˜ í…ìŠ¤íŠ¸)
                        context_type = "text"
                        context_info = {}
                        
                        # í‘œ ì»¨í…ìŠ¤íŠ¸ ê°ì§€
                        if any(keyword in sentence.lower() for keyword in ["table", "training cost", "bleu", "model", "baseline"]):
                            context_type = "table"
                            # ì£¼ë³€ í…ìŠ¤íŠ¸ì—ì„œ í‘œ ì œëª©ì´ë‚˜ ì„¤ëª… ì°¾ê¸°
                            for para in paragraphs:
                                if "table" in para.lower() and any(str(cite) in para for cite in unique_citations):
                                    table_match = re.search(r'table\s*\d+[:\.]?\s*([^.]+)', para.lower())
                                    if table_match:
                                        context_info["table_caption"] = table_match.group(1).strip()
                                        break
                        
                        # ê·¸ë¦¼/Figure ì»¨í…ìŠ¤íŠ¸ ê°ì§€
                        elif any(keyword in sentence.lower() for keyword in ["figure", "fig", "shown in", "depicted"]):
                            context_type = "figure"
                            figure_match = re.search(r'figure\s*\d+', sentence.lower())
                            if figure_match:
                                context_info["figure_reference"] = figure_match.group(0)
                        
                        # ìˆ˜ì‹ ì»¨í…ìŠ¤íŠ¸ ê°ì§€
                        elif any(symbol in sentence for symbol in ["\\", "equation", "formula", "=", "â‰¡"]):
                            context_type = "equation"
                        
                        citation_sentences.append({
                            "sentence": sentence,
                            "citation_numbers": unique_citations,
                            "full_paragraph": paragraph_text,
                            "context_type": context_type,
                            "context_info": context_info
                        })
                        
                        # ì „ì²´ ì¸ìš© ëª©ë¡ì— ì¶”ê°€
                        for citation_num in unique_citations:
                            all_citations.add(citation_num)
        
        # ì¤‘ë³µ ì œê±°ëœ ì¸ìš© ë²ˆí˜¸ë“¤
        unique_citations_list = sorted(list(all_citations), key=lambda x: int(x) if x.isdigit() else float('inf'))
        
        print(f"    âœ… ì„¹ì…˜ ì™„ë£Œ: {len(unique_citations_list)}ê°œ ê³ ìœ  ì¸ìš©, {len(citation_sentences)}ê°œ ì¸ìš© ë¬¸ì¥")
        if len(paragraphs) == 0:
            print(f"    âš ï¸ ê²½ê³ : ì´ ì„¹ì…˜ì—ì„œ ë¬¸ë‹¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            print(f"    ğŸ“ ìˆ˜ì§‘ëœ ìš”ì†Œ: {len(content_elements)}ê°œ")
        
        return {
            'paragraphs': paragraphs,
            'full_text': full_text.strip(),
            'citations': unique_citations_list,
            'citation_sentences': citation_sentences,
            'total_citations': len(unique_citations_list),
            'total_citation_instances': len(citation_sentences),
            'table_contexts': table_contexts
        }
    
    def extract_full_document(self) -> Dict:
        """ì „ì²´ ë¬¸ì„œë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„ì„"""
        print("ğŸ¯ ì „ì²´ ë¬¸ì„œ ë¶„ì„ ì‹œì‘")
        
        soup = self.fetch_html()
        sections = self.extract_sections(soup)
        
        all_sections_data = []
        total_citations = set()
        total_citation_instances = []
        
        for i, section in enumerate(sections):
            print(f"\nğŸ“– ì„¹ì…˜ {i+1}/{len(sections)} ì²˜ë¦¬ ì¤‘: {section['full_title']}")
            
            # ë‹¤ìŒ ì„¹ì…˜ ì°¾ê¸°
            next_section_elem = None
            if i + 1 < len(sections):
                next_section_elem = sections[i + 1]['element']
            
            # ì„¹ì…˜ ë‚´ìš© ì¶”ì¶œ
            content = self.extract_section_content(section['element'], next_section_elem)
            
            section_data = {
                'section_info': {
                    'section_number': section['section_number'],
                    'section_title': section['section_title'],
                    'full_title': section['full_title'],
                    'section_type': section['section_type'],
                    'parent_section': section.get('parent_section', None)
                },
                'content': content
            }
            
            all_sections_data.append(section_data)
            
            # ì „ì²´ í†µê³„ ëˆ„ì 
            total_citations.update(content['citations'])
            total_citation_instances.extend(content['citation_sentences'])
            
            print(f"  âœ… ì„¹ì…˜ ì™„ë£Œ: {content['total_citations']}ê°œ ê³ ìœ  ì¸ìš©, {content['total_citation_instances']}ê°œ ì¸ìš© ë¬¸ì¥")
        
        # ì „ì²´ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        all_text = " ".join([section['content']['full_text'] for section in all_sections_data])
        all_paragraphs = []
        for section in all_sections_data:
            all_paragraphs.extend(section['content']['paragraphs'])
        
        result = {
            'arxiv_id': self.arxiv_id,
            'document_info': {
                'total_sections': len(all_sections_data),
                'total_paragraphs': len(all_paragraphs),
                'total_word_count': len(all_text.split()),
                'unique_citations': len(total_citations),
                'total_citation_instances': len(total_citation_instances)
            },
            'sections': all_sections_data,
            'global_summary': {
                'all_citations': sorted(list(total_citations), key=lambda x: int(x) if x.isdigit() else 999),
                'all_citation_sentences': total_citation_instances,
                'full_document_text': all_text
            }
        }
        
        print(f"\nğŸ‰ ì „ì²´ ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ!")
        print(f"  ğŸ“– ì´ ì„¹ì…˜: {result['document_info']['total_sections']}ê°œ")
        print(f"  ğŸ“„ ì´ ë¬¸ë‹¨: {result['document_info']['total_paragraphs']}ê°œ")
        print(f"  ğŸ“Š ê³ ìœ  ì¸ìš©: {result['document_info']['unique_citations']}ê°œ")
        print(f"  ğŸ¯ ì¸ìš© ì¸ìŠ¤í„´ìŠ¤: {result['document_info']['total_citation_instances']}ê°œ")
        
        return result
    
    def save_to_json(self, data: Dict, filename: str = "full_document_analysis.json"):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        filepath = os.path.join(os.path.dirname(__file__), filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {filepath}")
        return filepath

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ arXiv HTML í¬ë¡¤ë§ ì‹œì‘ - ì „ì²´ ë¬¸ì„œ ë¶„ì„")
    print("="*60)
    
    crawler = ArxivHTMLCrawler()
    
    try:
        # ì „ì²´ ë¬¸ì„œ ë¶„ì„
        full_doc_data = crawler.extract_full_document()
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        crawler.save_to_json(full_doc_data)
        
        # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“‹ ì „ì²´ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼:")
        print(f"  ğŸ“– ì´ ì„¹ì…˜: {full_doc_data['document_info']['total_sections']}")
        print(f"  ğŸ“„ ì´ ë¬¸ë‹¨: {full_doc_data['document_info']['total_paragraphs']}")
        print(f"  ğŸ“ ì´ ë‹¨ì–´: {full_doc_data['document_info']['total_word_count']}")
        print(f"  ğŸ“Š ê³ ìœ  ì¸ìš© ë…¼ë¬¸: {full_doc_data['document_info']['unique_citations']}ê°œ")
        print(f"  ğŸ¯ ì´ ì¸ìš© ì¸ìŠ¤í„´ìŠ¤: {full_doc_data['document_info']['total_citation_instances']}ê°œ")
        
        print(f"\nğŸ“š ì¸ìš©ëœ ë…¼ë¬¸ ë²ˆí˜¸ë“¤: {full_doc_data['global_summary']['all_citations']}")
        
        print("\nğŸ“– ì„¹ì…˜ë³„ ìš”ì•½:")
        for i, section in enumerate(full_doc_data['sections'], 1):
            info = section['section_info']
            content = section['content']
            print(f"  {i}. [{info['section_type']}] {info['full_title']}")
            print(f"     - ì¸ìš©: {content['total_citations']}ê°œ, ì¸ìš©ë¬¸ì¥: {content['total_citation_instances']}ê°œ")
        
        print(f"\nâœ… ì „ì²´ ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ! full_document_analysis.json íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 