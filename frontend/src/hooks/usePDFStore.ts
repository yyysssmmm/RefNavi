'use client';

import { useState, useCallback, useEffect } from 'react';
import { PDFFile, AnalysisResult, Reference, ChatMessage } from '@/types';
import { generateId } from '@/lib/utils';
import { 
  savePDFToStorage, 
  loadPDFFromStorage, 
  saveAnalysisToStorage, 
  loadAnalysisFromStorage,
  clearStorageData 
} from '@/lib/storage';

export function usePDFStore() {
  const [currentPDF, setCurrentPDF] = useState<PDFFile | null>(null);
  const [analysisResult, setAnalysisResult] = useState<AnalysisResult | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [selectedReference, setSelectedReference] = useState<Reference | null>(null);
  const [chatMessages, setChatMessages] = useState<ChatMessage[]>([]);
  const [isChatOpen, setIsChatOpen] = useState(false);
  const [showPDFViewer, setShowPDFViewer] = useState(false);
  const [isLoaded, setIsLoaded] = useState(false);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ localStorageì—ì„œ ë°ì´í„° ë³µì›
  useEffect(() => {
    console.log('usePDFStore ì´ˆê¸°í™” - localStorageì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...');
    
    // ê¸°ì¡´ ë°ì´í„° í˜•ì‹ê³¼ í˜¸í™˜ì„± ë¬¸ì œë¡œ í•œ ë²ˆ í´ë¦¬ì–´ (ê°œë°œ ì¤‘ì—ë§Œ)
    const hasOldFormat = localStorage.getItem('refnavi_pdf_file');
    if (hasOldFormat) {
      try {
        const oldData = JSON.parse(hasOldFormat);
        if (!oldData.data) {
          console.log('ğŸ”„ êµ¬ í˜•ì‹ ë°ì´í„° ê°ì§€ - localStorage í´ë¦¬ì–´');
          clearStorageData();
        }
      } catch (e) {
        console.log('ğŸ”„ ì˜ëª»ëœ ë°ì´í„° í˜•ì‹ - localStorage í´ë¦¬ì–´:', e);
        clearStorageData();
      }
    }
    
    const storedPDF = loadPDFFromStorage();
    const storedAnalysis = loadAnalysisFromStorage();
    
    if (storedPDF) {
      setCurrentPDF(storedPDF);
      console.log('âœ… ì €ì¥ëœ PDF ë³µì›ë¨:', storedPDF.name, '(ì‹¤ì œ ë°ì´í„° í¬í•¨)');
    }
    
    if (storedAnalysis) {
      setAnalysisResult(storedAnalysis);
      console.log('âœ… ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ ë³µì›ë¨');
    }
    
    setIsLoaded(true);
  }, []);

  const uploadPDF = useCallback((file: File) => {
    console.log('usePDFStore.uploadPDF í˜¸ì¶œë¨:', file.name);
    
    const pdfFile: PDFFile = {
      file,
      name: file.name,
      size: file.size,
      url: URL.createObjectURL(file),
      uploadedAt: new Date(),
    };
    
    console.log('PDFFile ê°ì²´ ìƒì„±:', pdfFile);
    setCurrentPDF(pdfFile);
    
    // localStorageì— ì €ì¥
    savePDFToStorage(pdfFile);
    console.log('setCurrentPDF ë° localStorage ì €ì¥ ì™„ë£Œ');
  }, []);

  const startAnalysis = useCallback(async () => {
    if (!currentPDF) return;
    
    setIsAnalyzing(true);
    
    // ì„ì‹œ ëª©ì—… ë°ì´í„° (ì‹¤ì œë¡œëŠ” ë°±ì—”ë“œ API í˜¸ì¶œ)
    setTimeout(() => {
      const mockResult: AnalysisResult = {
        references: [
          {
            id: 1,
            title: "Attention Is All You Need",
            authors: ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"],
            year: 2017,
            venue: "Advances in Neural Information Processing Systems",
            citationCount: 97523,
            doi: "10.5555/3295222.3295349",
            abstract: "ì´ ë…¼ë¬¸ì—ì„œëŠ” ì˜¤ì§ attention ë©”ì»¤ë‹ˆì¦˜ì—ë§Œ ê¸°ë°˜í•œ ìƒˆë¡œìš´ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ì¸ Transformerë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. RNNì´ë‚˜ CNNì„ ì™„ì „íˆ ë°°ì œí•˜ë©´ì„œë„ ê¸°ê³„ë²ˆì—­ì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ë³‘ë ¬í™”ê°€ ê°€ëŠ¥í•˜ê³  í•™ìŠµ ì‹œê°„ë„ í¬ê²Œ ë‹¨ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ ìµœì‹  ì–¸ì–´ ëª¨ë¸ì˜ ê¸°ë°˜ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤."
          },
          {
            id: 2,
            title: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            authors: ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"],
            year: 2018,
            venue: "NAACL-HLT",
            citationCount: 68420,
            doi: "10.18653/v1/N19-1423",
            abstract: "BERTëŠ” ëª¨ë“  ì¸µì—ì„œ ì¢Œìš° ë¬¸ë§¥ì„ ëª¨ë‘ ê³ ë ¤í•˜ëŠ” ê¹Šì€ ì–‘ë°©í–¥ í‘œí˜„ì„ ì‚¬ì „ í›ˆë ¨í•˜ëŠ” ìƒˆë¡œìš´ ì–¸ì–´ í‘œí˜„ ëª¨ë¸ì…ë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ëœ BERTëŠ” ì§ˆì˜ì‘ë‹µ, ì–¸ì–´ ì¶”ë¡  ë“± ë‹¤ì–‘í•œ ìì—°ì–´ì²˜ë¦¬ íƒœìŠ¤í¬ì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤."
          },
          {
            id: 3,
            title: "GPT-3: Language Models are Few-Shot Learners",
            authors: ["Tom B. Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared Kaplan"],
            year: 2020,
            venue: "Advances in Neural Information Processing Systems",
            citationCount: 42156,
            doi: "10.5555/3495724.3496261",
            abstract: "GPT-3ëŠ” 1750ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ìë™íšŒê·€ ì–¸ì–´ ëª¨ë¸ë¡œ, ë‹¤ì–‘í•œ NLP íƒœìŠ¤í¬ì—ì„œ ëª‡ ê°œì˜ ì˜ˆì‹œë§Œìœ¼ë¡œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë³„ë„ì˜ íŒŒì¸íŠœë‹ ì—†ì´ë„ ë²ˆì—­, ì§ˆì˜ì‘ë‹µ, ì°½ì‘ ë“±ì—ì„œ ì¸ê°„ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤."
          },
          {
            id: 4,
            title: "ResNet: Deep Residual Learning for Image Recognition",
            authors: ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"],
            year: 2016,
            venue: "IEEE Conference on Computer Vision and Pattern Recognition",
            citationCount: 95832,
            doi: "10.1109/CVPR.2016.90",
            abstract: "ì”ì°¨ ì—°ê²°ì„ ë„ì…í•œ ê¹Šì€ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ì¸ ResNetì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ì—¬ ë§¤ìš° ê¹Šì€ ë„¤íŠ¸ì›Œí¬(152ì¸µ)ì˜ í›ˆë ¨ì„ ê°€ëŠ¥í•˜ê²Œ í–ˆìœ¼ë©°, ImageNetì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤."
          },
          {
            id: 23,
            title: "Adam: A Method for Stochastic Optimization",
            authors: ["Diederik P. Kingma", "Jimmy Ba"],
            year: 2014,
            venue: "International Conference on Learning Representations",
            citationCount: 78542,
            doi: "10.48550/arXiv.1412.6980",
            abstract: "í™•ë¥ ì  ëª©ì í•¨ìˆ˜ ìµœì í™”ë¥¼ ìœ„í•œ Adam ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì ì‘ì  í•™ìŠµë¥ ì„ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ì¸ ìµœì í™”ë¥¼ ì œê³µí•˜ë©°, ëŒ€ë¶€ë¶„ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œ í‘œì¤€ ì˜µí‹°ë§ˆì´ì €ë¡œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤."
          },
          {
            id: 24,
            title: "Dropout: A Simple Way to Prevent Neural Networks from Overfitting",
            authors: ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"],
            year: 2014,
            venue: "Journal of Machine Learning Research",
            citationCount: 45623,
            doi: "10.5555/2627435.2670313",
            abstract: "ë“œë¡­ì•„ì›ƒì€ ì‹ ê²½ë§ì˜ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ì •ê·œí™” ê¸°ë²•ì…ë‹ˆë‹¤. í›ˆë ¨ ì¤‘ ë¬´ì‘ìœ„ë¡œ ë‰´ëŸ°ì„ ì œê±°í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
          }
        ],
        citations: [
          {
            id: '1',
            sentence: 'Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences [2,19].',
            section: 'Introduction',
            context: 'Establishing the importance of attention mechanisms in sequence modeling',
            references: ['1', '3'],
          },
          {
            id: '2',
            sentence: 'long short-term memory [13] and gated recurrent [7] networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems',
            section: 'Introduction', 
            context: 'Describing current state-of-the-art sequence modeling approaches',
            references: ['2'],
          },
        ],
        summary: {
          totalReferences: 3,
          totalCitations: 2,
          sections: ['Introduction', 'Background', 'Model Architecture'],
        },
      };
      
      setAnalysisResult(mockResult);
      saveAnalysisToStorage(mockResult);
      setIsAnalyzing(false);
      console.log('ë¶„ì„ ì™„ë£Œ ë° localStorage ì €ì¥ë¨');
    }, 2000);
  }, [currentPDF]);

  const addChatMessage = useCallback((content: string, type: 'user' | 'assistant' = 'user') => {
    const message: ChatMessage = {
      id: generateId(),
      type,
      content,
      timestamp: new Date(),
    };
    setChatMessages(prev => [...prev, message]);
  }, []);

  const toggleChat = useCallback(() => {
    setIsChatOpen(prev => !prev);
  }, []);

  const togglePDFViewer = useCallback(() => {
    setShowPDFViewer(prev => !prev);
  }, []);

  const reset = useCallback(() => {
    setCurrentPDF(null);
    setAnalysisResult(null);
    setIsAnalyzing(false);
    setSelectedReference(null);
    setChatMessages([]);
    setIsChatOpen(false);
    setShowPDFViewer(false);
    
    // localStorageë„ í´ë¦¬ì–´
    clearStorageData();
    console.log('ëª¨ë“  ìƒíƒœ ë° localStorage í´ë¦¬ì–´ë¨');
  }, []);

  return {
    // State
    currentPDF,
    analysisResult,
    isAnalyzing,
    selectedReference,
    chatMessages,
    isChatOpen,
    showPDFViewer,
    isLoaded, // ì´ˆê¸° ë¡œë”© ì™„ë£Œ ì—¬ë¶€
    
    // Actions
    uploadPDF,
    startAnalysis,
    setSelectedReference,
    addChatMessage,
    toggleChat,
    togglePDFViewer,
    reset,
  };
} 